{"cells":[{"cell_type":"markdown","metadata":{"id":"iUMM_uUCmLW8"},"source":["## **Evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":37982,"status":"ok","timestamp":1687475442821,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"5ziC45_cSfu9"},"outputs":[],"source":["from src.training_utils import *\n","from src.summarizers import MemSum\n","from tqdm import tqdm\n","from rouge_score import rouge_scorer\n","import json\n","import numpy as np\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5877,"status":"ok","timestamp":1687475448695,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"bcAh047kSjLj"},"outputs":[],"source":["rouge_cal = rouge_scorer.RougeScorer(\n","    ['rouge1', 'rouge2', 'rougeLsum'], use_stemmer=True)\n","\n","\n","model_eval = 'one_head' # Three modes\n","\n","gpu = True #torch.cuda.is_available()\n","\n","if model_eval == 'glove':\n","    pegasus_mode = False\n","    model_path = \"src/model/MemSum_Full/PubMed/memsum/model_batch_1169370.pt\"\n","    embed_dim = 200\n","    two_heads = False\n","\n","elif model_eval == 'one_head':\n","    pegasus_mode = True\n","    model_path = \"src/model/MemSum_Full/PubMed/one_head/model_batch_1003000.pt\"\n","    embed_dim = 768\n","    two_heads = False\n","elif model_eval == 'two_heads':\n","    pegasus_mode = True\n","    model_path = \"src/model/MemSum_Full/PubMed/two_heads/model_batch_735000.pt\"\n","    embed_dim = 768\n","    two_heads = True\n","\n","\n","\n","\n","\n","pubmed_test_data = \"src/data/PubMed/test_PUBMED.jsonl\"\n","\n","\n","if two_heads:\n","    with open(\"src/data/PubMed/Test_ExtAbs_PUBMED.json\") as f:\n","        pubmed_test_data = json.load(f)\n","\n","\n","memsum_custom_data = MemSum(model_path,\n","                            \"src/model/glove/vocabulary_200dim.pkl\",\n","                            gpu=gpu,  max_doc_len=100, pegasus_mode=pegasus_mode, embed_dim=embed_dim, two_heads = two_heads)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1687475449246,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"Dryz67c9mJN6"},"outputs":[],"source":["if not two_heads:\n","    test_corpus_custom_data = [ json.loads(line) for line in open(pubmed_test_data)]\n","else:\n","    test_corpus_custom_data = pubmed_test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1687475449247,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"c6f3Up_1UiWz"},"outputs":[],"source":["def order_sentences(shuffled_list, ordered_numbers):\n","    paired_list = list(zip(ordered_numbers, shuffled_list))\n","\n","    sorted_list = sorted(paired_list, key=lambda x: x[0])\n","\n","    ordered_sentences = [pair[1] for pair in sorted_list]\n","\n","    return ordered_sentences[0]\n","\n","\n","def evaluate( model, corpus, p_stop, max_extracted_sentences, rouge_cal ):\n","    scores = []\n","    for data in tqdm(corpus):\n","        \n","        # print(\"original text: \\n\", data['text'])\n","        # for el in data['text']:\n","        #     print(el + '\\n')\n","        \n","        if not two_heads:\n","            gold_summary = data[\"summary\"]\n","            extracted_summary = model.extract( [data[\"text\"]], p_stop_thres = p_stop, return_sentence_position = True, max_extracted_sentences_per_document = max_extracted_sentences )\n","        else:\n","            gold_summary = data[1][\"summary\"]\n","            gold_abstract = data[0][\"abstract\"]\n","            # print(\"Gold abstract: \\n\", gold_abstract)\n","\n","            extracted_summary = model.extract( data, p_stop_thres = p_stop, return_sentence_position = True, max_extracted_sentences_per_document = max_extracted_sentences )\n","        # print(\"Gold summary: \\n\", gold_summary)\n","        extracted_summary = order_sentences(extracted_summary[0], extracted_summary[1])\n","        \n","        print(\"Extracted Summary: \", extracted_summary)\n","        score = rouge_cal.score( \"\\n\".join( gold_summary ), \"\\n\".join(extracted_summary)  )\n","        scores.append( [score[\"rouge1\"].fmeasure, score[\"rouge2\"].fmeasure, score[\"rougeLsum\"].fmeasure ] )\n","        break\n","    return np.asarray(scores).mean(axis = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1687475449248,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"zI9ap4ABmeqj"},"outputs":[],"source":["evaluate( memsum_custom_data, test_corpus_custom_data, 0.6, 7, rouge_cal)"]},{"cell_type":"markdown","metadata":{},"source":["### Code to plot the validation results stored in WandB"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Data for ROUGE-1, ROUGE-2, and ROUGE-L\n","rouge1_memsum = [0.4672, 0.4672, 0.4734, 0.4734, 0.4773, 0.4780, 0.4780, 0.4801, 0.4802, 0.4799, 0.4811, 0.4810, 0.4821, 0.4824, 0.4819]\n","rouge2_memsum = [0.2126, 0.2125, 0.2167, 0.2166, 0.2191, 0.2199, 0.2198, 0.2217, 0.2218, 0.2213, 0.2224, 0.2230, 0.2236, 0.2236, 0.2233]\n","rougeL_memsum = [0.4260, 0.4260, 0.4309, 0.4309, 0.4349, 0.4345, 0.4345, 0.4370, 0.4371, 0.4361, 0.4377, 0.4376, 0.4390, 0.4384, 0.4374]\n","\n","rouge1_transformer = [0.4727, 0.4759, 0.4800, 0.4800, 0.4786, 0.4787, 0.4807, 0.4813, 0.4794, 0.4831, 0.4829, 0.4834]\n","rouge2_transformer = [0.2177, 0.2219, 0.2246, 0.2246, 0.2245, 0.2245, 0.2241, 0.2258, 0.2245, 0.2271, 0.2266, 0.2262]\n","rougeL_transformer = [0.4332, 0.4361, 0.4396, 0.4395, 0.4386, 0.4387, 0.4401, 0.4414, 0.4400, 0.4427, 0.4421, 0.4417]\n","\n","rouge1_transformer_cross = [0.4627, 0.4687, 0.4619, 0.4707, 0.4455, 0.4405, 0.4447, 0.4448, 0.4403, 0.4376, 0.4354, 0.4379, 0.4367]\n","rouge2_transformer_cross = [0.2069, 0.2110, 0.2082, 0.2136, 0.1936, 0.192, 0.194, 0.1932, 0.1909, 0.1880, 0.1865, 0.1885]\n","rougeL_transformer_cross = [0.4233, 0.4292, 0.4204, 0.4306, 0.4077, 0.4002, 0.4042, 0.4054, 0.3997, 0.3970, 0.3934, 0.3967, 0.3952]\n","\n","fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 10))  # Adjust the figsize as needed\n","\n","# ROUGE-1\n","sns.lineplot(data=[rouge1_memsum, rouge1_transformer, rouge1_transformer_cross], ax=axes[0])\n","axes[0].set_title(\"ROUGE-1\")\n","axes[0].legend(['MS Vanilla', 'MS Transformer', 'MS Transformer+ Cross Attn'])\n","\n","# ROUGE-2\n","sns.lineplot(data=[rouge2_memsum, rouge2_transformer, rouge2_transformer_cross], ax=axes[1])\n","axes[1].set_title(\"ROUGE-2\")\n","axes[1].legend(['MS Vanilla', 'MS Transformer', 'MS Transformer+ Cross Attn'])\n","\n","# ROUGE-L\n","sns.lineplot(data=[rougeL_memsum, rougeL_transformer, rougeL_transformer_cross], ax=axes[2])\n","axes[2].set_title(\"ROUGE-L\")\n","axes[2].legend(['MS Vanilla', 'MS Transformer', 'MS Transformer+ Cross Attn'])\n","\n","# Adjust layout\n","plt.tight_layout()\n","plt.savefig(\"rouge_results.pdf\")\n","# Display the plot\n","plt.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOW/QDszJuQpc0BBO1ViM2+","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"}},"nbformat":4,"nbformat_minor":0}
