{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !pip install -r requirements.txt -q\n","from src.training_utils import *"]},{"cell_type":"markdown","metadata":{"id":"Ahd-LU31L2Xr"},"source":["## **MemSum + Pegasus Encoder**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76030,"status":"ok","timestamp":1687475404875,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"wPnWLxpkMYLy","outputId":"d16d857b-4abe-4411-cce9-70ab615ee4a1"},"outputs":[],"source":["!python src/src/MemSum_Full/train.py -pegasus_mode True -training_corpus_file_name src/data/PubMed_truncated/train_PUBMED_labelled.jsonl -validation_corpus_file_name src/data/PubMed_truncated/val_PUBMED.jsonl -model_folder src/model/MemSum_Full/PubMed_truncated/run0/ -log_folder src/log/MemSum_Full/PubMed_truncated/run0/ -vocabulary_file_name src/model/glove/vocabulary_200dim.pkl -pretrained_unigram_embeddings_file_name src/model/glove/unigram_embeddings_200dim.pkl -max_seq_len 100 -max_doc_len 150 -num_of_epochs 10 -save_every 1000 -n_device 1 -batch_size_per_device 1 -max_extracted_sentences_per_document 7 -moving_average_decay 0.999 -p_stop_thres 0.6\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### The model that was used is [PEGASUS-BASE](https://huggingface.co/google/pegasus-x-base)\n","* Load the model and the tokenizer"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-x-base\")\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-x-base\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* This is how the decoder works"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["India â€” easy on grounds) air and central and and and and and not air))))))))))))))))))))))))))))))))\n"]}],"source":["input_text = \"Studies have shown that owning a dog has numerous benefits.\"\n","\n","# Tokenize the input text\n","input_tokens = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True)\n","\n","output_tokens = model.generate(\n","    input_tokens.input_ids,\n","    decoder_start_token_id=model.config.pad_token_id,\n","    max_length=50,  # Set the desired maximum length of the generated output\n","    num_beams=1,  # Number of beams for beam search\n","    early_stopping=True,  # Stop generation when all beams have reached the end token\n",")\n","\n","# Decode the generated output tokens\n","decoded_output = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n","\n","print(decoded_output)"]},{"cell_type":"markdown","metadata":{},"source":["* This is how the encoder works"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 100])\n"]}],"source":["\n","# Example input text\n","input_text = [\"Studies have shown that owning a dog has numerous benefits.\",\n","              \"hi how are you?\"]\n","\n","# Tokenize the input text\n","input_tokens = tokenizer(input_text, return_tensors=\"pt\",\n","                         truncation=True, max_length=100,\n","                         padding='max_length'\n","                         )\n","print(input_tokens['input_ids'].shape)\n","# Pass the input through the encoder\n","encoder_outputs = model.model.encoder(**input_tokens)\n","\n","# # Access the encoder outputs\n","# encoder_last_hidden_state = encoder_outputs.last_hidden_state\n","# print(encoder_last_hidden_state.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.to('cuda')\n","t = torch.randint(0, 100, size = (1, 100*100), device = 'cuda')\n","t2 = torch.randint(0, 1, size = (1, 100*100), device = 'cuda')\n","input_tok = {}\n","input_tok['input_ids'] = t\n","input_tok['attention_mask'] = t2\n","model.model.encoder(**input_tok)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.model.decoder"]},{"cell_type":"markdown","metadata":{"id":"iUMM_uUCmLW8"},"source":["## **Evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":37982,"status":"ok","timestamp":1687475442821,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"5ziC45_cSfu9"},"outputs":[],"source":["from src.MemSum.summarizers import MemSum\n","from tqdm import tqdm\n","from rouge_score import rouge_scorer\n","import json\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5877,"status":"ok","timestamp":1687475448695,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"bcAh047kSjLj"},"outputs":[],"source":["rouge_cal = rouge_scorer.RougeScorer(\n","    ['rouge1', 'rouge2', 'rougeLsum'], use_stemmer=True)\n","\n","memsum_custom_data = MemSum(\"src/MemSum/model/MemSum_Full/custom_data/200dim/run3/model_batch_1000_pegs.pt\",\n","                            \"src/MemSum/model/glove/vocabulary_200dim.pkl\",\n","                            gpu=True,  max_doc_len=500, pegasus_mode=True, embed_dim=768)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1687475449246,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"Dryz67c9mJN6"},"outputs":[],"source":["test_corpus_custom_data = [ json.loads(line) for line in open(\"src/MemSum/data/custom_data/test_CUSTOM_raw.jsonl\")]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1687475449247,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"c6f3Up_1UiWz"},"outputs":[],"source":["def evaluate( model, corpus, p_stop, max_extracted_sentences, rouge_cal ):\n","    scores = []\n","    for data in tqdm(corpus):\n","        gold_summary = data[\"summary\"]\n","        extracted_summary = model.extract( [data[\"text\"]], p_stop_thres = p_stop, max_extracted_sentences_per_document = max_extracted_sentences )[0]\n","\n","        score = rouge_cal.score( \"\\n\".join( gold_summary ), \"\\n\".join(extracted_summary)  )\n","        scores.append( [score[\"rouge1\"].fmeasure, score[\"rouge2\"].fmeasure, score[\"rougeLsum\"].fmeasure ] )\n","\n","    return np.asarray(scores).mean(axis = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1687475449248,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"zI9ap4ABmeqj"},"outputs":[],"source":["evaluate( memsum_custom_data, test_corpus_custom_data, 0.6, 7, rouge_cal)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOW/QDszJuQpc0BBO1ViM2+","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
