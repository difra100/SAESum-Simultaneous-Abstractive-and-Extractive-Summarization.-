{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#%pip install -r requirements.txt \n","from src.training_utils import * "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ahd-LU31L2Xr"},"source":["## **MemSum + Pegasus Encoder**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76030,"status":"ok","timestamp":1687475404875,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"wPnWLxpkMYLy","outputId":"d16d857b-4abe-4411-cce9-70ab615ee4a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mantonio-scard97\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/anto/SAESum-Simultaneous_Abstractive_and_Extractive_Summarization/wandb/run-20230629_194309-pw002lx6\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvivid-shadow-20\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/antonio-scard97/SAESUM-Abstractive_Extractive_Summarization\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/antonio-scard97/SAESUM-Abstractive_Extractive_Summarization/runs/pw002lx6\u001b[0m\n","True\n","83233it [00:02, 36612.23it/s]\n","4676it [00:00, 5236.59it/s]\n","PegasusTokenizerFast(name_or_path='google/pegasus-x-base', vocab_size=96103, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask_2>', 'additional_special_tokens': ['<mask_1>', '<unk_2>', '<unk_3>', '<unk_4>', '<unk_5>', '<unk_6>', '<unk_7>', '<unk_8>', '<unk_9>', '<unk_10>', '<unk_11>', '<unk_12>', '<unk_13>', '<unk_14>', '<unk_15>', '<unk_16>', '<unk_17>', '<unk_18>', '<unk_19>', '<unk_20>', '<unk_21>', '<unk_22>', '<unk_23>', '<unk_24>', '<unk_25>', '<unk_26>', '<unk_27>', '<unk_28>', '<unk_29>', '<unk_30>', '<unk_31>', '<unk_32>', '<unk_33>', '<unk_34>', '<unk_35>', '<unk_36>', '<unk_37>', '<unk_38>', '<unk_39>', '<unk_40>', '<unk_41>', '<unk_42>', '<unk_43>', '<unk_44>', '<unk_45>', '<unk_46>', '<unk_47>', '<unk_48>', '<unk_49>', '<unk_50>', '<unk_51>', '<unk_52>', '<unk_53>', '<unk_54>', '<unk_55>', '<unk_56>', '<unk_57>', '<unk_58>', '<unk_59>', '<unk_60>', '<unk_61>', '<unk_62>', '<unk_63>', '<unk_64>', '<unk_65>', '<unk_66>', '<unk_67>', '<unk_68>', '<unk_69>', '<unk_70>', '<unk_71>', '<unk_72>', '<unk_73>', '<unk_74>', '<unk_75>', '<unk_76>', '<unk_77>', '<unk_78>', '<unk_79>', '<unk_80>', '<unk_81>', '<unk_82>', '<unk_83>', '<unk_84>', '<unk_85>', '<unk_86>', '<unk_87>', '<unk_88>', '<unk_89>', '<unk_90>', '<unk_91>', '<unk_92>', '<unk_93>', '<unk_94>', '<unk_95>', '<unk_96>', '<unk_97>', '<unk_98>', '<unk_99>', '<unk_100>', '<unk_101>', '<unk_102>']}, clean_up_tokenization_spaces=True)\n","PegasusTokenizerFast(name_or_path='google/pegasus-x-base', vocab_size=96103, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask_2>', 'additional_special_tokens': ['<mask_1>', '<unk_2>', '<unk_3>', '<unk_4>', '<unk_5>', '<unk_6>', '<unk_7>', '<unk_8>', '<unk_9>', '<unk_10>', '<unk_11>', '<unk_12>', '<unk_13>', '<unk_14>', '<unk_15>', '<unk_16>', '<unk_17>', '<unk_18>', '<unk_19>', '<unk_20>', '<unk_21>', '<unk_22>', '<unk_23>', '<unk_24>', '<unk_25>', '<unk_26>', '<unk_27>', '<unk_28>', '<unk_29>', '<unk_30>', '<unk_31>', '<unk_32>', '<unk_33>', '<unk_34>', '<unk_35>', '<unk_36>', '<unk_37>', '<unk_38>', '<unk_39>', '<unk_40>', '<unk_41>', '<unk_42>', '<unk_43>', '<unk_44>', '<unk_45>', '<unk_46>', '<unk_47>', '<unk_48>', '<unk_49>', '<unk_50>', '<unk_51>', '<unk_52>', '<unk_53>', '<unk_54>', '<unk_55>', '<unk_56>', '<unk_57>', '<unk_58>', '<unk_59>', '<unk_60>', '<unk_61>', '<unk_62>', '<unk_63>', '<unk_64>', '<unk_65>', '<unk_66>', '<unk_67>', '<unk_68>', '<unk_69>', '<unk_70>', '<unk_71>', '<unk_72>', '<unk_73>', '<unk_74>', '<unk_75>', '<unk_76>', '<unk_77>', '<unk_78>', '<unk_79>', '<unk_80>', '<unk_81>', '<unk_82>', '<unk_83>', '<unk_84>', '<unk_85>', '<unk_86>', '<unk_87>', '<unk_88>', '<unk_89>', '<unk_90>', '<unk_91>', '<unk_92>', '<unk_93>', '<unk_94>', '<unk_95>', '<unk_96>', '<unk_97>', '<unk_98>', '<unk_99>', '<unk_100>', '<unk_101>', '<unk_102>']}, clean_up_tokenization_spaces=True)\n","pad_index is:  1\n","0it [00:00, ?it/s]"]}],"source":["!python src/MemSum/src/MemSum_Full/train.py -pegasus_mode True -training_corpus_file_name src/MemSum/data/PubMed_truncated/train_PUBMED_labelled.jsonl -validation_corpus_file_name src/MemSum/data/PubMed_truncated/val_PUBMED.jsonl -model_folder src/MemSum/model/MemSum_Full/PubMed_truncated/run1/ -log_folder src/MemSum/log/MemSum_Full/PubMed_truncated/run3/ -vocabulary_file_name src/MemSum/model/glove/vocabulary_200dim.pkl -pretrained_unigram_embeddings_file_name src/MemSum/model/glove/unigram_embeddings_200dim.pkl -max_seq_len 100 -max_doc_len 150 -num_of_epochs 10 -save_every 1000 -n_device 1 -batch_size_per_device 1 -max_extracted_sentences_per_document 7 -moving_average_decay 0.999 -p_stop_thres 0.6\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### The model that was used is [PEGASUS-BASE](https://huggingface.co/google/pegasus-x-base)\n","* Load the model and the tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-x-base\")\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-x-base\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* This is how the decoder works"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_text = \"Studies have shown that owning a dog has numerous benefits.\"\n","\n","# Tokenize the input text\n","input_tokens = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True)\n","\n","output_tokens = model.generate(\n","    input_tokens.input_ids,\n","    decoder_start_token_id=model.config.pad_token_id,\n","    max_length=50,  # Set the desired maximum length of the generated output\n","    num_beams=1,  # Number of beams for beam search\n","    early_stopping=True,  # Stop generation when all beams have reached the end token\n",")\n","\n","# Decode the generated output tokens\n","decoded_output = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n","\n","print(decoded_output)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* This is how the encoder works"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Example input text\n","input_text = [\"Studies have shown that owning a dog has numerous benefits.\",\n","              \"hi how are you?\"]\n","\n","# Tokenize the input text\n","input_tokens = tokenizer(input_text, return_tensors=\"pt\",\n","                         truncation=True, max_length=100,\n","                         padding='max_length'\n","                         )\n","print(input_tokens['input_ids'].shape)\n","# Pass the input through the encoder\n","encoder_outputs = model.model.encoder(**input_tokens)\n","\n","# # Access the encoder outputs\n","# encoder_last_hidden_state = encoder_outputs.last_hidden_state\n","# print(encoder_last_hidden_state.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.to('cuda')\n","t = torch.randint(0, 100, size = (1, 100*100), device = 'cuda')\n","t2 = torch.randint(0, 1, size = (1, 100*100), device = 'cuda')\n","input_tok = {}\n","input_tok['input_ids'] = t\n","input_tok['attention_mask'] = t2\n","model.model.encoder(**input_tok)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.model.decoder"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iUMM_uUCmLW8"},"source":["## **Evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":37982,"status":"ok","timestamp":1687475442821,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"5ziC45_cSfu9"},"outputs":[],"source":["from src.MemSum.summarizers import MemSum\n","from tqdm import tqdm\n","from rouge_score import rouge_scorer\n","import json\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5877,"status":"ok","timestamp":1687475448695,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"bcAh047kSjLj"},"outputs":[],"source":["rouge_cal = rouge_scorer.RougeScorer(\n","    ['rouge1', 'rouge2', 'rougeLsum'], use_stemmer=True)\n","\n","memsum_custom_data = MemSum(\"src/MemSum/model/MemSum_Full/custom_data/200dim/run3/model_batch_1000_pegs.pt\",\n","                            \"src/MemSum/model/glove/vocabulary_200dim.pkl\",\n","                            gpu=True,  max_doc_len=500, pegasus_mode=True, embed_dim=768)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1687475449246,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"Dryz67c9mJN6"},"outputs":[],"source":["test_corpus_custom_data = [ json.loads(line) for line in open(\"src/MemSum/data/custom_data/test_CUSTOM_raw.jsonl\")]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1687475449247,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"c6f3Up_1UiWz"},"outputs":[],"source":["def evaluate( model, corpus, p_stop, max_extracted_sentences, rouge_cal ):\n","    scores = []\n","    for data in tqdm(corpus):\n","        gold_summary = data[\"summary\"]\n","        extracted_summary = model.extract( [data[\"text\"]], p_stop_thres = p_stop, max_extracted_sentences_per_document = max_extracted_sentences )[0]\n","\n","        score = rouge_cal.score( \"\\n\".join( gold_summary ), \"\\n\".join(extracted_summary)  )\n","        scores.append( [score[\"rouge1\"].fmeasure, score[\"rouge2\"].fmeasure, score[\"rougeLsum\"].fmeasure ] )\n","\n","    return np.asarray(scores).mean(axis = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1687475449248,"user":{"displayName":"antonio scardino","userId":"15834533576282944930"},"user_tz":-120},"id":"zI9ap4ABmeqj"},"outputs":[],"source":["evaluate( memsum_custom_data, test_corpus_custom_data, 0.6, 7, rouge_cal)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOW/QDszJuQpc0BBO1ViM2+","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
