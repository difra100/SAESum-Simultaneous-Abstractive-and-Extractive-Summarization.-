{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pegasus Encoder Decoder**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdifra00\u001b[0m (\u001b[33mdeepl_wizards\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peppe/Desktop/Università/Projects/SAESum-Simultaneous_Abstractive_and_Extractive_Summarization/wandb/run-20230630_212410-u64oj2jv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deepl_wizards/SAESUM-Abstractive_Extractive_Summarization/runs/u64oj2jv' target=\"_blank\">rosy-shadow-18</a></strong> to <a href='https://wandb.ai/deepl_wizards/SAESUM-Abstractive_Extractive_Summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deepl_wizards/SAESUM-Abstractive_Extractive_Summarization' target=\"_blank\">https://wandb.ai/deepl_wizards/SAESUM-Abstractive_Extractive_Summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deepl_wizards/SAESUM-Abstractive_Extractive_Summarization/runs/u64oj2jv' target=\"_blank\">https://wandb.ai/deepl_wizards/SAESUM-Abstractive_Extractive_Summarization/runs/u64oj2jv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %pip install accelerate -U\n",
    "# !pip install transformers[torch]\n",
    "# !pip install accelerate -U\n",
    "from src.training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.30.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Pubmed dataset which was downloaded to the local directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: pubmed-summarization/section\n",
      "Found cached dataset pubmed-summarization (/home/peppe/.cache/huggingface/datasets/ccdv___pubmed-summarization/section/1.0.0/f765ec606c790e8c5694b226814a13f1974ba4ea98280989edaffb152ded5e2b)\n",
      "100%|██████████| 3/3 [00:00<00:00, 957.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'abstract'],\n",
      "        num_rows: 119924\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'abstract'],\n",
      "        num_rows: 6633\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'abstract'],\n",
      "        num_rows: 6658\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "pubmed_dataset = load_dataset(\"ccdv/pubmed-summarization\")#, data_dir =\"/home/peppe/Desktop/Università/Projects/SAESum-Simultaneous_Abstractive_and_Extractive_Summarization/src/data/PubMed_abstractive\")\n",
    "print(pubmed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article': 'it occurs in more than 50% of patients and may reach 90% in certain types of cancers , especially in patients undergoing chemotherapy and/or radiation therapy.1 anemia is defined as an inadequate circulating level of hemoglobin ( hb ) ( hb < 12 g / dl ) and may arise as a result of the underlying disease , bleeding , poor nutrition , chemotherapy , or radiation therapy . \\n preliminary studies suggest that survival and loco - regional control after radiation therapy , especially in head and neck cancers , may be compromised by anemia.24 anemia often worsens symptoms such as fatigue , weakness , and dyspnea , and thus may have a negative effect on quality of life ( qol ) and performance status in patients with cancer . \\n thus , to improve physical functioning , qol , and prognosis in patients with cancer , it would be reasonable to take a proactive approach in identifying populations who need treatment for cancer - associated anemia ( caa ) and provide timely management . \\n blood transfusion is an effective way to replace depleted hb within a short period , but the effect is , unfortunately , temporary and can cause serious adverse risks and increased mortality . in randomized clinical trials in patients with caa \\n , erythropoiesis - stimulating agents ( esas ) produced significant increases in hb level , decreased transfusion requirements , and improved qol.57 however , 30%50% of patients do not respond to such agents . \\n in addition , the use of esas often causes concern about severe adverse reactions.6,8 in several studies , esas were found to shorten overall survival time , or time to tumor progression in patients whose hb level reached more than 12 g / dl . \\n these studies included patients with different primary cancers , such as breast , lung , head and neck , cervix , and lymphomas.911 the lack of response to erythropoietin stimulation in patients with cancer is partly attributed to the functional iron deficiency state , in which the high rate of erythropoiesis exceeds the delivery of usable iron , despite adequate iron stores.12 absolute iron deficiency , in contrast , occurs when iron delivery is impaired because iron stores are depleted ( serum ferritin , < 100 ng / ml ; transferring saturation , < 20%).13 hepcidin , a peptide hormone produced by the liver , is up - regulated in chronic inflammatory states including cancer . \\n hepcidin inhibits iron transport across cell membranes , thus decreasing the accessibility of stored iron and gastrointestinal absorption of dietary iron , leading to an increased frequency of iron - restricted erythropoiesis.1416 many randomized trials examined the role of intravenous ( iv ) iron in addition to esas in the treatment of anemia in patients with cancer . \\n many of these studies showed improvement in esa response , time to maximal response , reduction in esa dose , and improvement in qol parameters ( when measured ) in favor of the combination over esas alone . \\n the observed benefit was independent of baseline iron parameters.1721 one study found a 36% reduction in the number of patients transfused.21 this pilot study assessed the efficacy and feasibility of iv iron monotherapy in patients with cancer who have anemia and who are undergoing treatment with chemotherapy and/or radiation therapy without the use of esas . \\n patients received the study treatment for 12 weeks followed by a 4-week follow - up period . \\n eligible patients were at least 18 years old , about to start a cycle of chemotherapy and/or radiation therapy within 1 week of inclusion , and had a nonmyeloid malignancy , hb levels of 11.0 g / dl or less , a life expectancy of more than 24 weeks , and an eastern cooperative oncology group performance status of 02 . \\n patients were also required to have a serum ferritin level of 100 ng / ml or higher or transferrin saturation ( tsat ) levels of 15% or higher and to have received no esas or iv iron therapy within 30 days and no oral iron therapy ( 27 mg / day or more ) within 7 days before enrollment . \\n patients were excluded for leukoerythroblastic features on blood film , hemolysis , gastrointestinal bleeding , folate or vitamin b12 deficiency , elevated serum ferritin ( 900 ng / ml ) or transferrin saturation ( tsat ) ( 35% ) levels , pregnancy or lactation , liver dysfunction ( grade 2 or higher based on national cancer institute common toxicity criteria ) , renal dysfunction ( serum creatinine levels 2.0 mg / dl ) , active infection requiring systemic antibiotics , personal or family history of hemochromatosis , comorbidities precluding study participation , hypersensitivity to iv iron , red blood cell transfusion within the last 2 weeks , or any investigational agent within 30 days before enrollment . \\n patients were not allowed to take any vitamin , mineral , or herbal supplements containing 27 mg or more of iron per day or 100 mg vitamin c per day during the study or follow - up period . \\n blood transfusions were permitted at the primary physician s discretion if hb levels decreased to 8 g / dl or less , and such patients were considered treatment failures . \\n written informed consent was provided by all patients before study participation , and the protocol and supporting documents were approved by the institutional review board of king hussein cancer center . \\n the study was conducted in accordance with the declaration of helsinki and good clinical practice as contained in the us code of federal regulations that governs the protection of human subjects and the obligations of clinical investigators . \\n patients received 200 mg ferric hydroxide sucrose diluted in 100 ml normal saline and infused over the course of 1 hour weekly for a total of 12 weeks . the first dose was given during the first clinic visit ( 4 days from the initiation of chemotherapy or radiation therapy ) . \\n tsat was monitored , as protocol mandated withholding iron therapy when tsat levels were higher than 50% . at the first clinic visit ( week 1 ; baseline ) , a blood sample was obtained for laboratory assessments before the study treatment was started . \\n patients attended weekly clinic visits for treatment and assessment ; and returned for follow - up visits at week 14 which included a complete physical examination . \\n complete blood count and tsat were done every 3 weeks , and again 2 weeks after last treatment ( week 14 ) . \\n complete laboratory assessment ( hb , serum ferritin , reticulocyte count , transferrin , tsat , serum iron , total iron binding capacity , red cell indices , white blood cell count with differential , platelet count , and serum chemistries ) were done at week 1 and at week 14 ( end of study ) . \\n adverse events were assessed at each clinic visit until study completion or withdrawal , and during the 30 days after the last study treatment . \\n hb test results were presented as mean , median , and range through all 12 weeks . \\n comparison between means of hb level were made between the baseline hb and hb levels in the following weeks , using t - test . a significance criterion of p < 0.05 was used in the analysis . \\n all analyses were performed using sas version 9.1 ( sas institute inc , cary , nc , usa ) . \\n patients received the study treatment for 12 weeks followed by a 4-week follow - up period . \\n eligible patients were at least 18 years old , about to start a cycle of chemotherapy and/or radiation therapy within 1 week of inclusion , and had a nonmyeloid malignancy , hb levels of 11.0 g / dl or less , a life expectancy of more than 24 weeks , and an eastern cooperative oncology group performance status of 02 . \\n patients were also required to have a serum ferritin level of 100 ng / ml or higher or transferrin saturation ( tsat ) levels of 15% or higher and to have received no esas or iv iron therapy within 30 days and no oral iron therapy ( 27 mg / day or more ) within 7 days before enrollment . \\n patients were excluded for leukoerythroblastic features on blood film , hemolysis , gastrointestinal bleeding , folate or vitamin b12 deficiency , elevated serum ferritin ( 900 ng / ml ) or transferrin saturation ( tsat ) ( 35% ) levels , pregnancy or lactation , liver dysfunction ( grade 2 or higher based on national cancer institute common toxicity criteria ) , renal dysfunction ( serum creatinine levels 2.0 mg / dl ) , active infection requiring systemic antibiotics , personal or family history of hemochromatosis , comorbidities precluding study participation , hypersensitivity to iv iron , red blood cell transfusion within the last 2 weeks , or any investigational agent within 30 days before enrollment . \\n patients were not allowed to take any vitamin , mineral , or herbal supplements containing 27 mg or more of iron per day or 100 mg vitamin c per day during the study or follow - up period . \\n blood transfusions were permitted at the primary physician s discretion if hb levels decreased to 8 g / dl or less , and such patients were considered treatment failures . \\n written informed consent was provided by all patients before study participation , and the protocol and supporting documents were approved by the institutional review board of king hussein cancer center . \\n the study was conducted in accordance with the declaration of helsinki and good clinical practice as contained in the us code of federal regulations that governs the protection of human subjects and the obligations of clinical investigators . \\n patients received 200 mg ferric hydroxide sucrose diluted in 100 ml normal saline and infused over the course of 1 hour weekly for a total of 12 weeks . \\n the first dose was given during the first clinic visit ( 4 days from the initiation of chemotherapy or radiation therapy ) . \\n tsat was monitored , as protocol mandated withholding iron therapy when tsat levels were higher than 50% . \\n at the first clinic visit ( week 1 ; baseline ) , a blood sample was obtained for laboratory assessments before the study treatment was started . \\n patients attended weekly clinic visits for treatment and assessment ; and returned for follow - up visits at week 14 which included a complete physical examination . \\n complete blood count and tsat were done every 3 weeks , and again 2 weeks after last treatment ( week 14 ) . \\n complete laboratory assessment ( hb , serum ferritin , reticulocyte count , transferrin , tsat , serum iron , total iron binding capacity , red cell indices , white blood cell count with differential , platelet count , and serum chemistries ) were done at week 1 and at week 14 ( end of study ) . \\n adverse events were assessed at each clinic visit until study completion or withdrawal , and during the 30 days after the last study treatment . \\n hb test results were presented as mean , median , and range through all 12 weeks . \\n comparison between means of hb level were made between the baseline hb and hb levels in the following weeks , using t - test . a significance criterion of p < 0.05 was used in the analysis . \\n all analyses were performed using sas version 9.1 ( sas institute inc , cary , nc , usa ) . \\n twenty - five patients ( 17 women and 8 men ) were eligible , consented , and included in the study ; their mean age ( standard deviation , [ sd ] ) was 56 years ( 13.0 years ) . \\n chemotherapy varied according to the primary cancer and included anthracycline , platinum , taxanes , cyclophosphamide , high - dose ifosfamide , vincristine , vinblastine , bleomycin , and others . \\n many of the included patients had their chemotherapy treatment as second- or third - line therapy . \\n patients characteristics , including age , primary tumor , and active anticancer treatment are summarized in table 1 . \\n one patient died during the study from his tumor ( after week 2 ) , and five patients withdrew from the study because of inconvenience ( three after week 3 , and two after week 4 ) . \\n nineteen ( 76.0% ) patients completed a minimum of three treatments , 15 ( 60.0% ) completed nine treatments , and 14 ( 56.0% ) completed all twelve planned weekly treatments . \\n as seen in table 2 , the mean hb level of the 25 patients at baseline was 9.6 g / dl ( median , 9.9 g / dl ; range , 6.9 g / dl10.9 g / dl ) . for the 15 patients who completed at least nine treatments , the mean change in their hb level was 1.7 g / dl ( median , 1.1 g / dl ; range , 1.9 g / dl to 3.2 g / dl ) . \\n for the 14 patients who completed the whole treatment period ( 12 weeks ) , the mean hb level change was 2.1 g / dl ( median , 1.3 g / dl ; range , 0.2 g / dl to 4.6 g / dl ; p = 0.0007 ) . \\n eight ( 42.1% ) of the 19 patients who completed at least three iron infusions had a more than 1 g / dl increase in their hb level . \\n hemoglobin level changes for the 14 patients who completed twelve iron infusions are shown in figure 1 . \\n no iv iron - related adverse events were reported among patients during the study or the follow - up period . \\n tsat was monitored during the study period , and no patients had tsat levels increase to more than 50% . \\n the highest ferritin level among patients who completed at least nine iv iron treatments was 1,170 ng / ml ; the mean level at the end of study period for the whole group was 379 ng / ml . \\n five ( 20.0% ) patients received blood transfusions and were considered treatment failures ( three after week 3 , transfused at hb levels of 6.9 g / dl , 7.8 g / dl , and 5.4 g / dl ; one after week 4 , transfused at an hb level of 8.2 g / dl ; and one after week 9 , transfused at an hb level of 7.2 g / dl ) . \\n low hb levels are associated with diminished qol and possibly decreased overall survival.2 successful treatment of anemia has undeniable benefits for patients , often yielding dramatic symptomatic improvement . \\n although the role of esas is well - established in treating caa , big concerns were recently raised about the negative effect of esas on survival in some patients with cancer.911 concerns about the risk for thromboembolism in patients with cancer with higher hb levels who are receiving esa were also addressed in many trials.22,23 in addition , the possible immunosuppressive effects of blood product transfusions that may have relevance to neoplasia progression were addressed before.24 , 25 in our pilot study , we tested the feasibility of using iron supplementation alone to treat anemia in patients with cancer who are undergoing chemotherapy without the use of esas or blood transfusion , which could be a valid alternative , especially for patients with curable cancers . \\n oral iron is easier to administer and relatively inexpensive , but low patient adherence , poor enteral absorption , and poor tolerance because of a wide range of troublesome gastrointestinal adverse effects limit its overall effectiveness.26 anemia of chronic disease may occur in patients with cancer and is associated with an increase in hepcidin levels , which decreases oral iron absorption and bone marrow iron use , negating any possible effect of regular doses of oral iron.15 iv iron therapy significantly improves response to epoetin alfa when compared with oral iron or no iron in anemic patients with cancer who are receiving chemotherapy.1721 oral iron supplements with esas showed no significant benefit over esas alone in treating caa.21 sodium ferric gluconate and iron sucrose appear to have more favorable safety profiles over iron dextran . \\n a large prospective safety comparison trial failed to show serious anaphylactoid reactions,27 which is confirmed in our study , in which no patients developed reactions and no patients withdrew from the study because of adverse effects . given that the mean hb increase using esas with iv iron in one large controlled trial was 2.4 g / dl,21 the results obtained in our study are clinically significant . \\n these findings should be further confirmed and better assessed in larger studies , in which questions such as the optimal timing of iv iron therapy with respect to chemotherapy and the optimal total dose of iv iron should be determined . \\n the use of iv iron monotherapy was recently reviewed by a group in germany that studied the use of ferric carboxymaltose to replace esa and blood transfusions as a treatment for caa . \\n iron - deficient patients treated with ferric carboxymaltose alone ( n = 233 ) had a median of 1.4 g / dl increase in hemoglobin levels compared with those receiving additional treatment with esas ( n = 46 ; median , 1.6 g / dl ) . our study , \\n however , is peculiar in using iron therapy in a non - iron - deficiency state.28 iron overload after iv iron therapy , with potential concerns about the risk of developing secondary cancers and infection , might be raised . \\n the highest serum ferritin level in the present study in patients who completed at least 9 weeks of iv iron therapy was 1,170 ng / ml . most of the literature addressing cancer and infections in iron - overloaded patients comes from patients with hemochromatosis or patients who are undergoing hemodialysis . \\n published reviews report an increase in hepatocellular carcinoma only in patients with hemochromatosis after they develop cirrhosis.29 similarly data supporting the association between iv iron therapy and higher infection rate are weak and not well - supported.30 in fact , anemia itself is a risk factor for infections in patients receiving hemodialysis.31 a multivariate analysis of associations between iron and mortality in more than 58,000 patients receiving hemodialysis reported no increased death rate from serum ferritin levels as high as 1,200 ng / ml.30 the increasing cost of therapy in patients with cancer is of grave concern , which could be an additional benefit of iv iron over the use of esas in such patients . to further address many of the questions raised , \\n our team is planning a bigger trial for iv iron in patients with cancer who have anemia to confirm the results discussed in this pilot trial . \\n in addition , we will be looking into predictors of response to iv iron , such as serum hepcidin level . \\n iv iron therapy alone is safe and may be effective in improving hb levels in patients with cancer who are undergoing active anticancer therapy . \\n further randomized trials are needed to address many of the questions raised in our pilot study .', 'abstract': 'backgroundanemia in patients with cancer who are undergoing active therapy is commonly encountered and may worsen quality of life in these patients . the effect of blood transfusion is often temporary and may be associated with serious adverse events . \\n erythropoiesis - stimulating agents are not effective in 30%50% of patients and may have a negative effect on overall survival.aimsto assess the efficacy and feasibility of intravenous iron therapy in patients with cancer who have non - iron - deficiency anemia and who are undergoing treatment with chemotherapy without the use of erythropoiesis - stimulating agents.methodsadult patients with solid cancers and non - iron - deficiency anemia were included . \\n ferric sucrose at a dose of 200 mg was given in short intravenous infusions weekly for a total of 12 weeks . \\n hemoglobin level was measured at baseline , every 3 weeks , and 2 weeks after the last iron infusion ( week 14 ) . \\n adverse events related to intravenous iron were prospectively reported.resultsof 25 patients included , 19 ( 76.0% ) completed at least three iron infusions and 14 ( 56.0% ) finished the planned 12 weeks of therapy . \\n the mean hemoglobin level of the 25 patients at baseline was 9.6 g / dl ( median , 9.9 g / dl ; range , 6.9 g / dl 10.9 g / dl ) . the mean change in hemoglobin level for the 15 patients who completed at least 9 treatments was 1.7 g / dl ( median , 1.1 g / dl ; range , 1.9 g / dl to 3.2 g / dl ) ; it reached 2.1 g / dl ( median , 1.3 g / dl ; range , 0.2 g / dl to 4.6 g / dl ; p = 0.0007 ) for the 14 patients who completed all 12 weekly treatments . \\n five ( 20.0% ) patients were transfused and considered as treatment failures . \\n no treatment - related adverse events were reported.conclusionintravenous iron treatment alone is safe and may reduce blood transfusion requirements and improve hemoglobin level in patients with cancer who are undergoing anticancer therapy . \\n further randomized studies are needed to confirm these findings .'}\n",
      "{'article': 'small non - coding rnas are transcribed into mrna but remain untranslated in eukaryotic cells . \\n they include sirna ( small interfering rna ) , mirna ( microrna ) , pirna ( piwi - interacting rna ) and snorna ( small nucleolar rna ) . \\n mirnas are a class of multifunctional singled - stranded small rna which are ~20  nt in length and regulate the stability or translational efficiency of targeted messenger rna depending on the base - pairing complementarity between the mirna and its target mrna [ 1 , 2 ] . although over 1,000 mirna sequences have been identified from the tissues or cells of human origin and other species , as many as 1,000 to 10,000 mirnas per genome have been predicted [ 3 , 4 ] . \\n mirnas regulate a broad range of biological processes including timing of development , cell cycle progression , stem cell self - renewal , differentiation , cancer initiation , cancer cell proliferation , metastasis and apoptosis [ 511 ] . \\n cancer is caused by multiple processes including uncontrolled cellular proliferation and inappropriate survival of apoptotic cells . \\n many regulatory factors switch on or off genes that govern cell division and direct cellular proliferation . \\n mirnas regulate gene expression and play important roles in the onset and progression of tumorigenesis . \\n emerging evidence demonstrates the involvement of mirna in mammary gland tumorigenesis , functioning either as tumor suppressors or oncogenes . \\n although the current treatment of radiation therapy , chemotherapy and hormone therapy slow mammary gland tumor growth , prolong survival and improve the quality of patients life , metastatic breast cancer still remains incurable due to our limited understanding of the molecular mechanisms through which tumorigenesis and metastasis occur . \\n as small non - coding rnas regulate gene expression and tumorigenesis , they may represent a novel cancer therapy . \\n unlike mrna , mirnas are transcribed but never translated . some mirnas are transcribed from non - coding regions between genes , deriving from independent transcription unit . \\n other mirnas are transcribed together with coding mrnas from the coding region of the genome , deriving from the introns of gene transcripts [ 13 , 14 ] . \\n mirna gene copy number gain / loss and mirna gene mutation have been observed in breast cancer resulting in the aberrant expression of mirna . \\n the first study about the altered expression of mirnas in human breast cancer patients and human breast cancer cell lines was reported in 2005 by lorio et al . , \\n in which 29 mirnas were identified with aberrant expression based on microarray and northern blot analysis of 76 breast tumor samples and 14 human breast cell lines . \\n zhang and colleagues analyzed 283 human mirna genes on 55 human breast primary tumors and 18 human breast cancer cell lines using array - based comparative genomic hybridization . \\n the results demonstrated a high frequency ( ~72.8% ) of gene copy number abnormality in mirna - containing regions in human breast cancer . \\n wang et al . collected 68 patients with newly diagnosed breast cancer and examined the expression of selected mirnas in tumor and adjacent non - tumor tissues . \\n mir-21 , mir-106a and mir-155 were significantly over - expressed in the tumor specimens compared with normal controls , whereas mir-126 , mir-199a and mir-335 were significantly decreased in expression in the tumor samples . \\n our studies of the mir-17 - 92 cluster demonstrated decreased expression of mir-17/20 in human breast cancer specimens compared with matching normal breast tissue from the same patient . \\n subsequent analysis identified reduced mir-17/20 expression in node - positive compared with node - negative breast cancers and demonstrated that mir-17/20 inhibited breast cancer cell migration and invasion via a heterotypic signaling . \\n although the tendency for a global decrease of mirna expression in human cancers originally suggested a general tumor suppressor function of mirnas , subsequent studies showing the aberrant expression of specific mirnas in breast cancer suggest mirna - specific roles in breast cancer onset and progression . \\n many distinct mirnas have been shown to regulate breast cancer cell proliferation , apoptosis , cancer stem cell expansion , and tumorigenesis . \\n mirna may function as either tumor suppressors or oncogenes depending on the cell type , culture conditions , target genes and pathway . \\n the involvement of mirna in mammary gland tumorigenesis has been reviewed recently [ 21 , 22 ] . \\n le et al . described the expression pattern and regulatory network of key mirnas in breast cancer , including let-7 , mir-34 , mir-125 , mir-200 family , mir-205 , mir-21 , mir-10 and the mir-17 - 92 cluster . \\n adams et al . reviewed the mirna regulation of estrogen signaling pathway and erbb2/her signaling pathway in breast cancer . \\n the understanding of how mirnas are involved in breast cancer through regulating the cell cycle remains rudimentary . \\n herein we summarize the recent literature and research progress on the mechanism by which mirnas regulate the breast cancer cell cycle and cellular proliferation ( fig . \\n 1mirna regulation of mammary gland tumorigenesis in control of the cell cycle . through targeting different genes and different cyclin / cdk complexes , mir-17/20 and \\n let-7 regulate the g1-s transition ; mir-21 and mir-27a regulate the g2-m checkpoint mirna regulation of mammary gland tumorigenesis in control of the cell cycle . through targeting different genes and different cyclin / cdk complexes , mir-17/20 and \\n let-7 regulate the g1-s transition ; mir-21 and mir-27a regulate the g2-m checkpoint cyclin d1 is either overexpressed or amplified in ~50% of breast cancer . \\n the abundance of cyclin d1 is rate - limiting in breast cancer cellular proliferation and g1-s phase transition [ 23 , 24 ] . \\n in addition , cyclin d1 is a critical downstream target of erbb2- , ras- and -catenin- induced breast cancers , and is sufficient for the induction of mammary tumors when targeted to the mammary gland of mice . \\n antisense inhibition of cyclin d1 expression in vivo suppressed the growth of neut - transformed mammary adenocarcinoma cells in nude mice . \\n conserved sequences of the cyclin d1 3utr contain potential binding sites for multiple mirnas including mir-17/20/106 , mir-15/16 , mir-23 and let-7 . \\n mir-17/20 binds the cyclin d1 3utr , inhibiting the expression of cyclin d1 , resulting in cell cycle arrest at the g1 phase and suppression of mcf-7 cell proliferation [ 18 , 26 ] . \\n the regulation of cyclin d1 expression by mir-17 - 92 , as well as mir-15/16 , was confirmed by deshpande et al . . \\n the let-7 family functions as a tumor suppressor in a variety of cancers including lung , colon , ovarian   and breast cancer . \\n schultz et al . demonstrated the downregulation of cyclin d1 by mirna let-7 in control of cancer cell growth . \\n the regulation of cyclin d1 by mirna is likely of broad importance as cyclin d1 encodes the regulatory subunit of a kinase that phosphorylates and inactivates the prb family proteins to inhibit dna synthesis , and phosphorylates nuclear respiratory factor 1 ( nrf-1 ) to inhibit mitochondria biogenesis [ 32 , 33 ] . \\n furthermore , cyclin d1 promotes breast epithelial cell angiogenesis and migration , and promotes chromosomal instability which in turn contributes to tumorigenesis . \\n the mir-221/222 cluster regulates the cell cycle , cell growth and epithelial - to - mesenchymal transition ( emt ) in breast cancer . \\n mir-221/222 inhibited p27 and p57 abundance , facilitating g1-s phase transition , thereby promoting cancer cell proliferation [ 36 , 37 ] . \\n moreover , mir-221/222 may contribute to the aggressive clinical behavior of basal - like breast cancers . \\n the breast cancer basal - like subtype - specific mirnas , mir-221 and mir-222 , promote emt in breast cancer by targeting trps1 ( trichorhinophalangeal syndrome type 1 ) which inhibits emt by repressing zeb2 expression . \\n mir-221 and/or mir-222 expression in mcf-7 and t47d breast cancer cells decreased er expression associated with tamoxifen resistance . \\n the onco - mirna mir-21 is overexpressed in a wide variety of cancers including breast cancer [ 40 , 41 ] . \\n mir-21 induced cellular proliferation , migration , invasion , emt , cancer stem cell characteristics and chemotherapy resistance in human breast cancer [ 42 , 43 ] . \\n high mir-21 level is associated with poor prognosis , advanced stage , positive lymph node status and reduced survival time in breast cancer . \\n mir-21 promotes mcf-7 cellular proliferation in part through inhibiting the expression of a tumor suppressor gene programmed cell death 4 ( pdcd4 ) . in colon cancer , \\n mir-21 participates in a dna damage - induced g2-m checkpoint through suppressing the cell cycle regulator cdc25a . \\n a recent report demonstrated the mir-21 regulates the cell cycle through targeting cdc25a in mcf-7 breast cancer cells . with a potential anti - cancer chemical 3,3-diindolylmethane treatment , \\n mir-27a expression is upregulated in human breast cancer cell lines . in mda - mb-231 cells , \\n mir-27a negatively regulated the zinc finger zbtb10 gene and myt-1 , thereby promoting breast cancer cell proliferation . \\n mir-27a suppressed myt-1 , increased cdc2/cyclin b activity and promoted the g2-m checkpoint in mda - mb-231 cells . thus , distinct mirnas affect key genetic targets that govern distinct cell - cycle checkpoints including cyclins , cdks , cdk inhibitors and the g2-m regulation apparatus . \\n in addition to cell - cycle control , breast tumor onset and progression and breast tumor stem cells are also regulated by distinct mirnas . \\n cancer stem cells ( cscs ) are characterized by their self - renewal capacity , an ability to differentiate into non - tumorigenic cell progeny , and their ability to seed tumors when transplanted into animal hosts . \\n cell surface markers such as cd44 , cd24 , cd133 , epithelial - specific antigen and aldehyde dehydrogenase-1 are frequently used to isolate and enrich cscs . \\n the involvement of mirnas in regulating tumor formation by cscs or tumor - initiating cells ( t - ic ) has been widely investigated . \\n let-7 expression is very low to undetectable level in embryonic stem cells ( es cells ) and increases with differentiation . \\n a comparison of mirna expression between breast t - ic and non - t - ic demonstrated reduced let-7 expression in t - ic and increased abundance with differentiation . \\n transduction of breast cscs with let-7 reduced the proportion of undifferentiated cells , inhibited cell proliferation , mammosphere formation , and tumor formation in vivo . \\n clarke and colleagues identified 37 mirnas which were differentially expressed between human breast cscs ( cd44cd24lineage ) and lineage nontumorigenic breast cancer cells . \\n the mir-200 family members were downregulated in human breast cscs and normal mammary stem / progenitor cells . \\n expression of mir-200 inhibited breast cancer stem cell expansion in vitro , and suppressed the tumor formation ability of human breast cancer stem cell in vivo . \\n ectopic mir-34c expression reduced breast t - ics self - renewal , inhibited emt and suppressed tumor cell invasiveness via silencing notch4 . \\n zhu et al . found the reduced mir-128 expression in human breast t - ic was accompanied by bmi-1 and abcc5 overexpression , and associated with chemotherapeutic resistance and poor survival . \\n enforced mir-128 expression increased the sensitivity of breast cancer cells to doxorubicin - induced apoptosis and dna damage . \\n emerging evidence has demonstrated the importance of cscs in cancer initiation , cancer metastasis and drug resistance . \\n cscs are believed to be one of the most promising targets for cure of cancer . \\n the discovery that non - coding rnas regulate cscs widens our understanding of cscs , and may provide potential novel strategies for breast cancer therapy . \\n deletion of chromosome 6q , including region 6q14-q16 , is frequently observed in breast cancer . \\n the small non - coding snorna u50 is a candidate tumor suppressor gene in the 6q14 - 16 region , playing a role in the development and/or progression of breast cancer . \\n genomic deletion and transcriptional downregulation of snorna u50 was detected in breast cancer cell lines . \\n re - expression of snorna u50 inhibited colony formation of the human breast cancer cells hs578 t and mda - mb-231 . \\n pirnas are small non - coding rna that form rna - protein complexes through interactions with piwi proteins . \\n pirna was initially discovered in germ line cells , and considered as germ line - specific small rnas . \\n emerging evidence indicates that pirna expression occurs in somatic cells [ 57 , 58 ] and piwil2 expression has been identified in human breast cancer cells . \\n high - throughput deep sequencing identified a group of small rnas matching pirna sequences in human breast cancer tissues and breast cancer cell lines . \\n the study of these non - coding small rnas in human cancer is just starting . \\n the identification of the expression signature of these non - coding small rnas in breast cancer subtypes , and an understanding of their functional significance to oncogene expression , tumor initiation and tumor cell metastasis may shed important new perspectives on the role of these non - coding small rnas in breast cancer . \\n small non - coding rna - based diagnostic and therapeutic applications for human cancer are expected in the near future . although tumor - targeted delivery and local administration are still major challenges to the practical application of gene therapy for cancer , mirna - based cancer therapeutic approaches are being established and tested in animal models . \\n synthetic mirna mimics or mirna expression vectors have been successfully applied to restore or overexpress mirna in vitro . chemically modified lna anti - sense mirna inhibitor and other approaches have been used to block mirna function in cells . \\n kim et al . recently reported significant anti - tumor effect of virus - mediated delivery of mir-145 combined with 5-fu to treat breast cancer . \\n intranasal delivery of let-7   and intravenous delivery of mir-34a mimics   for non - small - cell lung cancer treatment and a virus - mediated delivery of mir-26a for liver cancer treatment in mouse model   demonstrate the promise of mirna for treatment of cancer . \\n dysregulated expression of mirnas has implicated components of the non - coding genome as either oncogenes or tumor suppressors of breast cancer . \\n experimental evidence has shown specific mirnas regulating the initiation , progression , metastasis and drug resistance of breast cancer via control of the cell cycle , altering cellular proliferation , altering cellular apoptosis and/or controlling the population of tumor stem cells . dysregulated \\n mirna expression has also been observed in cancer associated fibroblasts ( caf ) and in the systemic circulation [ 65 , 66 ] . \\n the circulating mirnas have the potential to serve as novel diagnostic and prognostic biomarkers for breast cancer . \\n a specific subset of dysregulated mirnas in breast cancer cells may serve as targets for gene therapy either alone or as an adjuvant treatment to current clinical protocols for breast cancer patients .', 'abstract': 'small non - coding rnas include sirna , mirna , pirna and snorna . \\n the involvement of mirnas in the regulation of mammary gland tumorigenesis has been widely studied while the role for other small non - coding rnas remains unclear . here \\n we summarize the involvement of mirna in breast cancer onset and progression through regulating the cell cycle and cellular proliferation . \\n the regulation of breast cancer stem cells and tumor regeneration by mirna is reviewed . \\n in addition , the emerging evidence demonstrating the involvement of pirna and snorna in breast cancer is briefly described .'}\n"
     ]
    }
   ],
   "source": [
    "print(pubmed_dataset[\"train\"][1])\n",
    "print(pubmed_dataset[\"test\"][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PegasusTokenizerFast(name_or_path='google/pegasus-x-base', vocab_size=96103, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask_2>', 'additional_special_tokens': ['<mask_1>', '<unk_2>', '<unk_3>', '<unk_4>', '<unk_5>', '<unk_6>', '<unk_7>', '<unk_8>', '<unk_9>', '<unk_10>', '<unk_11>', '<unk_12>', '<unk_13>', '<unk_14>', '<unk_15>', '<unk_16>', '<unk_17>', '<unk_18>', '<unk_19>', '<unk_20>', '<unk_21>', '<unk_22>', '<unk_23>', '<unk_24>', '<unk_25>', '<unk_26>', '<unk_27>', '<unk_28>', '<unk_29>', '<unk_30>', '<unk_31>', '<unk_32>', '<unk_33>', '<unk_34>', '<unk_35>', '<unk_36>', '<unk_37>', '<unk_38>', '<unk_39>', '<unk_40>', '<unk_41>', '<unk_42>', '<unk_43>', '<unk_44>', '<unk_45>', '<unk_46>', '<unk_47>', '<unk_48>', '<unk_49>', '<unk_50>', '<unk_51>', '<unk_52>', '<unk_53>', '<unk_54>', '<unk_55>', '<unk_56>', '<unk_57>', '<unk_58>', '<unk_59>', '<unk_60>', '<unk_61>', '<unk_62>', '<unk_63>', '<unk_64>', '<unk_65>', '<unk_66>', '<unk_67>', '<unk_68>', '<unk_69>', '<unk_70>', '<unk_71>', '<unk_72>', '<unk_73>', '<unk_74>', '<unk_75>', '<unk_76>', '<unk_77>', '<unk_78>', '<unk_79>', '<unk_80>', '<unk_81>', '<unk_82>', '<unk_83>', '<unk_84>', '<unk_85>', '<unk_86>', '<unk_87>', '<unk_88>', '<unk_89>', '<unk_90>', '<unk_91>', '<unk_92>', '<unk_93>', '<unk_94>', '<unk_95>', '<unk_96>', '<unk_97>', '<unk_98>', '<unk_99>', '<unk_100>', '<unk_101>', '<unk_102>']}, clean_up_tokenization_spaces=True)\n",
      "{'input_ids': [[8087, 108, 136, 156, 5577, 147, 1], [182, 117, 372, 5577, 107, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n",
      "PegasusXForConditionalGeneration(\n",
      "  (model): PegasusXModel(\n",
      "    (shared): Embedding(96103, 768)\n",
      "    (encoder): PegasusXEncoder(\n",
      "      (embed_tokens): Embedding(96103, 768)\n",
      "      (embed_global): Embedding(128, 768)\n",
      "      (embed_positions): PegasusXSinusoidalPositionalEmbedding()\n",
      "      (layers): ModuleList(\n",
      "        (0): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): PegasusXEncoderLayer(\n",
      "          (self_attn): PegasusXGlobalLocalAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (global_self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): PegasusXDecoder(\n",
      "      (embed_tokens): Embedding(96103, 768)\n",
      "      (embed_positions): PegasusXSinusoidalPositionalEmbedding()\n",
      "      (layers): ModuleList(\n",
      "        (0): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): PegasusXDecoderLayer(\n",
      "          (self_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusXAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=96103, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_checkpoint = \"google/pegasus-x-base\" # Use pegasus-x-base-finetuned-xsum\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "print(tokenizer)\n",
    "print(tokenizer(text_target=[\"Hello, this one sentence!\", \"This is another sentence.\"]))\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationModule(name: \"rouge\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id=None)}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\n",
      "Calculates average rouge scores for a list of hypotheses and references\n",
      "Args:\n",
      "    predictions: list of predictions to score. Each prediction\n",
      "        should be a string with tokens separated by spaces.\n",
      "    references: list of reference for each prediction. Each\n",
      "        reference should be a string with tokens separated by spaces.\n",
      "    rouge_types: A list of rouge types to calculate.\n",
      "        Valid names:\n",
      "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
      "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
      "        `\"rougeLsum\"`: rougeLsum splits text using `\"\n",
      "\"`.\n",
      "        See details in https://github.com/huggingface/datasets/issues/617\n",
      "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
      "    use_aggregator: Return aggregates if this is set to True\n",
      "Returns:\n",
      "    rouge1: rouge_1 (f1),\n",
      "    rouge2: rouge_2 (f1),\n",
      "    rougeL: rouge_l (f1),\n",
      "    rougeLsum: rouge_lsum (f1)\n",
      "Examples:\n",
      "\n",
      "    >>> rouge = evaluate.load('rouge')\n",
      "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
      "    >>> references = [\"hello there\", \"general kenobi\"]\n",
      "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "\"\"\", stored examples: 0)\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "metric = load(\"rouge\")\n",
    "print(metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[114, 909, 11624, 1382, 2375, 120, 115, 2651, 110, 108, 47422, 143, 110, 38117, 233, 57468, 110, 158, 604, 404, 3629, 197, 371, 231, 195, 26364, 110, 108, 21472, 132, 11526, 70443, 111, 56744, 143, 13076, 233, 57424, 110, 158, 604, 195, 26364, 110, 108, 21472, 132, 11526, 72225, 115, 109, 1690, 1105, 110, 107, 115, 110, 35057, 114, 692, 790, 110, 58373, 281, 399, 2220, 115, 110, 116, 43449, 111, 35739, 33824, 19244, 2375, 19107, 113, 305, 76040, 110, 108, 110, 74760, 111, 48254, 110, 108, 118, 72225, 110, 108, 15713, 111, 10703, 110, 108, 4802, 110, 107, 109, 19107, 113, 40999, 790, 8225, 399, 4843, 404, 115, 40727, 8032, 6005, 135, 20177, 112, 30316, 110, 107, 53018, 21026, 692, 113, 8225, 399, 392, 115, 32043, 28064, 3264, 120, 30316, 113, 183, 4512, 135, 40999, 111, 580, 513, 1050, 110, 107, 6406, 246, 133, 3251, 233, 4087, 79876, 644, 111, 256, 319, 371, 233, 377, 3957, 113, 3085, 943, 242, 110, 107, 9939, 110, 108, 399, 5173, 962, 127, 850, 130, 109, 1146, 962, 110, 108, 278, 233, 827, 110, 107, 1146, 399, 2258, 431, 115, 109, 10381, 1653, 186, 127, 163, 181, 1574, 1409, 399, 5986, 962, 115, 1690, 1105, 110, 107, 115, 110, 80290, 110, 108, 399, 1217, 431, 2375, 142, 2757, 115, 12799, 55928, 110, 107, 115, 110, 35057, 114, 1146, 294, 425, 431, 143, 110, 34678, 47934, 110, 158, 117, 4440, 115, 8225, 1370, 113, 24249, 633, 112, 885, 149, 2111, 392, 110, 107, 802, 110, 108, 136, 431, 117, 146, 3047, 115, 58024, 111, 2111, 633, 113, 109, 461, 2114, 167, 223, 74019, 404, 122, 580, 15787, 233, 1500, 1288, 127, 146, 1622, 141, 110, 34678, 47934, 110, 107, 1670, 109, 872, 113, 5360, 115, 633, 606, 130, 24249, 117, 902, 197, 176, 633, 110, 108, 223, 392, 115, 24249, 633, 127, 146, 589, 2111, 111, 137, 4070, 425, 110, 107, 6255, 110, 108, 8579, 564, 113, 109, 110, 34678, 47934, 117, 1074, 197, 109, 3189, 2087, 6627, 118, 136, 779, 456, 110, 107, 21905, 110, 108, 1905, 113, 809, 113, 425, 3633, 148, 8408, 109, 9646, 113, 404, 2153, 110, 34678, 47934, 110, 107, 124, 109, 176, 561, 110, 108, 109, 205, 356, 156, 117, 4774, 113, 798, 143, 110, 65019, 110, 158, 113, 110, 35057, 110, 108, 162, 117, 1470, 118, 5234, 111, 876, 109, 3633, 118, 4635, 1370, 110, 107, 109, 4774, 113, 426, 143, 11434, 1467, 110, 158, 117, 29882, 109, 426, 1288, 113, 392, 111, 153, 426, 397, 110, 107, 7634, 1636, 110, 108, 466, 122, 10880, 110, 108, 133, 109, 13028, 1298, 124, 8579, 1932, 113, 392, 141, 748, 337, 113, 153, 328, 110, 107, 12304, 28573, 133, 163, 109, 868, 113, 13554, 111, 29882, 149, 817, 113, 219, 1636, 110, 107, 2929, 233, 2118, 4097, 117, 114, 427, 233, 451, 4703, 120, 25329, 115, 399, 1034, 116, 1067, 253, 130, 110, 34678, 47934, 110, 107, 115, 663, 112, 219, 1636, 110, 108, 8579, 9964, 113, 392, 110, 108, 153, 1119, 111, 2082, 110, 108, 117, 114, 221, 356, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[1688, 110, 151, 109, 799, 692, 140, 2777, 165, 112, 4676, 109, 1521, 113, 427, 5173, 6115, 451, 124, 8689, 1014, 124, 40999, 1932, 790, 399, 233, 4843, 404, 115, 32043, 28064, 110, 108, 110, 35057, 107, 46694, 111, 1625, 110, 151, 136, 437, 233, 562, 8579, 6115, 148, 174, 479, 317, 3390, 111, 3418, 124, 280, 61491, 1708, 111, 4367, 399, 3185, 111, 2220, 143, 624, 233, 1428, 231, 459, 110, 158, 451, 124, 8689, 1014, 115, 32043, 28064, 110, 108, 110, 35057, 110, 107, 109, 405, 735, 14134, 6627, 115, 481, 1370, 204, 114, 5752, 1019, 908, 466, 122, 8689, 11217, 2332, 115, 385, 112, 3395, 111, 2226, 8579, 6115, 110, 107, 118, 4051, 113, 5800, 113, 109, 6115, 874, 3059, 22500, 113, 1133, 121, 111, 450, 233, 6115, 195, 24434, 1711, 107, 56131, 151, 544, 5099, 113, 4370, 122, 513, 2977, 4224, 1074, 197, 8163, 8408, 2838, 244, 6115, 790, 2220, 143, 891, 3092, 46787, 110, 158, 110, 107, 802, 110, 108, 186, 195, 220, 1225, 852, 790, 3185, 132, 916, 1948, 110, 107, 109, 1021, 113, 149, 53018, 21026, 22500, 1545, 2838, 244, 6115, 302, 790, 2220, 111, 3185, 130, 210, 130, 115, 916, 1948, 110, 107, 109, 1133, 121, 111, 450, 233, 804, 798, 2843, 115, 302, 1211, 2375, 120, 109, 980, 1034, 116, 1077, 825, 2135, 148, 174, 2838, 1562, 135, 31197, 19173, 112, 89137, 22314, 143, 891, 110, 105, 26652, 39070, 107, 5409, 30540, 110, 151, 136, 692, 9126, 109, 866, 924, 111, 25463, 113, 399, 5986, 962, 1]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 256\n",
    "#DA MODIFICARFE PER PEGASUS FORSE\n",
    "def preprocess_function(examples):\n",
    "    inputs = [doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(text_target=examples[\"abstract\"], max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "preprocess_function(pubmed_dataset['train'][:1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/peppe/.cache/huggingface/datasets/ccdv___pubmed-summarization/section/1.0.0/f765ec606c790e8c5694b226814a13f1974ba4ea98280989edaffb152ded5e2b/cache-83fe1a3796a65436.arrow\n",
      "Loading cached processed dataset at /home/peppe/.cache/huggingface/datasets/ccdv___pubmed-summarization/section/1.0.0/f765ec606c790e8c5694b226814a13f1974ba4ea98280989edaffb152ded5e2b/cache-251fe14d67349aa9.arrow\n",
      "Loading cached processed dataset at /home/peppe/.cache/huggingface/datasets/ccdv___pubmed-summarization/section/1.0.0/f765ec606c790e8c5694b226814a13f1974ba4ea98280989edaffb152ded5e2b/cache-33ed9b12aba01fbd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[114, 909, 11624, 1382, 2375, 120, 115, 2651, 110, 108, 47422, 143, 110, 38117, 233, 57468, 110, 158, 604, 404, 3629, 197, 371, 231, 195, 26364, 110, 108, 21472, 132, 11526, 70443, 111, 56744, 143, 13076, 233, 57424, 110, 158, 604, 195, 26364, 110, 108, 21472, 132, 11526, 72225, 115, 109, 1690, 1105, 110, 107, 115, 110, 35057, 114, 692, 790, 110, 58373, 281, 399, 2220, 115, 110, 116, 43449, 111, 35739, 33824, 19244, 2375, 19107, 113, 305, 76040, 110, 108, 110, 74760, 111, 48254, 110, 108, 118, 72225, 110, 108, 15713, 111, 10703, 110, 108, 4802, 110, 107, 109, 19107, 113, 40999, 790, 8225, 399, 4843, 404, 115, 40727, 8032, 6005, 135, 20177, 112, 30316, 110, 107, 53018, 21026, 692, 113, 8225, 399, 392, 115, 32043, 28064, 3264, 120, 30316, 113, 183, 4512, 135, 40999, 111, 580, 513, 1050, 110, 107, 6406, 246, 133, 3251, 233, 4087, 79876, 644, 111, 256, 319, 371, 233, 377, 3957, 113, 3085, 943, 242, 110, 107, 9939, 110, 108, 399, 5173, 962, 127, 850, 130, 109, 1146, 962, 110, 108, 278, 233, 827, 110, 107, 1146, 399, 2258, 431, 115, 109, 10381, 1653, 186, 127, 163, 181, 1574, 1409, 399, 5986, 962, 115, 1690, 1105, 110, 107, 115, 110, 80290, 110, 108, 399, 1217, 431, 2375, 142, 2757, 115, 12799, 55928, 110, 107, 115, 110, 35057, 114, 1146, 294, 425, 431, 143, 110, 34678, 47934, 110, 158, 117, 4440, 115, 8225, 1370, 113, 24249, 633, 112, 885, 149, 2111, 392, 110, 107, 802, 110, 108, 136, 431, 117, 146, 3047, 115, 58024, 111, 2111, 633, 113, 109, 461, 2114, 167, 223, 74019, 404, 122, 580, 15787, 233, 1500, 1288, 127, 146, 1622, 141, 110, 34678, 47934, 110, 107, 1670, 109, 872, 113, 5360, 115, 633, 606, 130, 24249, 117, 902, 197, 176, 633, 110, 108, 223, 392, 115, 24249, 633, 127, 146, 589, 2111, 111, 137, 4070, 425, 110, 107, 6255, 110, 108, 8579, 564, 113, 109, 110, 34678, 47934, 117, 1074, 197, 109, 3189, 2087, 6627, 118, 136, 779, 456, 110, 107, 21905, 110, 108, 1905, 113, 809, 113, 425, 3633, 148, 8408, 109, 9646, 113, 404, 2153, 110, 34678, 47934, 110, 107, 124, 109, 176, 561, 110, 108, 109, 205, 356, 156, 117, 4774, 113, 798, 143, 110, 65019, 110, 158, 113, 110, 35057, 110, 108, 162, 117, 1470, 118, 5234, 111, 876, 109, 3633, 118, 4635, 1370, 110, 107, 109, 4774, 113, 426, 143, 11434, 1467, 110, 158, 117, 29882, 109, 426, 1288, 113, 392, 111, 153, 426, 397, 110, 107, 7634, 1636, 110, 108, 466, 122, 10880, 110, 108, 133, 109, 13028, 1298, 124, 8579, 1932, 113, 392, 141, 748, 337, 113, 153, 328, 110, 107, 12304, 28573, 133, 163, 109, 868, 113, 13554, 111, 29882, 149, 817, 113, 219, 1636, 110, 107, 2929, 233, 2118, 4097, 117, 114, 427, 233, 451, 4703, 120, 25329, 115, 399, 1034, 116, 1067, 253, 130, 110, 34678, 47934, 110, 107, 115, 663, 112, 219, 1636, 110, 108, 8579, 9964, 113, 392, 110, 108, 153, 1119, 111, 2082, 110, 108, 117, 114, 221, 356, 1]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = pubmed_dataset.map(preprocess_function, batched=True)\n",
    "print(tokenized_datasets[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
    "    # Extract a few results\n",
    "    wandb.log({'rouge1': result['rouge1'], 'rouge2': result['rouge2'], 'rougeL': result['rougeL'], 'rougeLsum': result['rougeLsum']})\n",
    "    \n",
    "\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "for param in trainer.model.model.encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1153/14991 [04:36<55:20,  4.17it/s]\n",
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/14991 [00:00<?, ?it/s]You're using a PegasusTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  3%|▎         | 500/14991 [01:32<44:52,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8529, 'learning_rate': 0.0004834567407110934, 'epoch': 0.03}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pegasus\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-x-large\")\n",
    "\n",
    "model_name = \"google/pegasus-x-base\"\n",
    "model_s = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "model_s.to(device)\n",
    "\n",
    "\n",
    "ARTICLE_TO_SUMMARIZE = (\n",
    "    \"PG&E stated it scheduled the blackouts in response to forecasts for high winds \"\n",
    "    \"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were \"\n",
    "    \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
    ")\n",
    "inputs = tokenizer(ARTICLE_TO_SUMMARIZE, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model_s.generate(inputs[\"input_ids\"])\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\"California's largest electricity provider has turned off power to hundreds of thousands of customers.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-x-base\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-x-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Studies have shown that owning a dog has numerous benefits.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "input_tokens = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "output_tokens = model.generate(\n",
    "    input_tokens.input_ids,\n",
    "    decoder_start_token_id=model.config.pad_token_id,\n",
    "    max_length=50,  # Set the desired maximum length of the generated output\n",
    "    num_beams=1,  # Number of beams for beam search\n",
    "    early_stopping=True,  # Stop generation when all beams have reached the end token\n",
    ")\n",
    "\n",
    "# Decode the generated output tokens\n",
    "decoded_output = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example input text\n",
    "input_text = [\"Studies have shown that owning a dog has numerous benefits.\",\n",
    "              \"hi how are you?\"]\n",
    "\n",
    "# Tokenize the input text\n",
    "input_tokens = tokenizer(input_text, return_tensors=\"pt\",\n",
    "                         truncation=True, max_length=100,\n",
    "                         padding='max_length'\n",
    "                         )\n",
    "print(input_tokens['input_ids'].shape)\n",
    "# Pass the input through the encoder\n",
    "encoder_outputs = model.model.encoder(**input_tokens)\n",
    "\n",
    "# # Access the encoder outputs\n",
    "# encoder_last_hidden_state = encoder_outputs.last_hidden_state\n",
    "# print(encoder_last_hidden_state.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
